---
title: 'DATA 622 - Homework #1'
author: "Zach Alexander"
date: "2/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, warning=FALSE, message=FALSE, echo=FALSE}
require(palmerpenguins)
require(dplyr)
require(ggplot2)
require(tibble)
require(tidyr)
require(tidyverse)
require(dplyr)
require(ggplot2)
require(ggfortify)
require(gridExtra)
require(GGally)
require(corrplot)
require(devtools)
require(caret)
require(regclass)
require(MASS)
require(pROC)
require(nnet)
require(modelr)
require(broom)
require(mnlogit)
require(mlogit)
```

***

#### Part 1: Logistic Regression with binary outcome


***


**A) The penguin dataset has a 'species' column. Please check how many categories you have in the species column. Conduct whatever data manipulation you need to do to be able to build a logistic regression with binary outcome. Please explain your reasoning behind your decision as you manipulate the outcome/dependent variable (species).**

***

First, we'll save the penguin dataset as a tibble so we can manipulate it easier in the next steps:

```{r, echo=FALSE}
penguins <- tibble(penguins)
```

Then, as mentioned above, we'll first have to identify the number of categories that make up the `species` column. We can do this by running the syntax below:

```{r}
summary(penguins$species)
```

As we can see above, it looks like there are three species present in this dataset. Therefore, in order to create a logistic regression with a binary outcome, we'll have to determine which two species should be combined. We can also see from this summary that there are a small number of Chinstrap penguins in this dataset. This may be a good initial indication that combining this species with either Adelie or Gentoo will be best. However, before doing so, we can also take a look at the summary of all of the variables in the dataset, as well as some of the interactions between our continuous variables, including `bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, and `body_mass_g`.  

```{r, echo=FALSE}
summary(penguins)
```

It looks like there are 11 individuals that have missing `sex` information, including two individuals in our dataset that have a large amount of NAs across most of the features. Therefore, I'll omit those from our analysis:

```{r}
penguins <- na.omit(penguins)
```

Next, we can create plots that show interactions between some of our continous variables:
```{r, fig.height=16, fig.width=10, echo=FALSE, warning=FALSE}
plot1 <- ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, col = species)) +
    geom_point() + 
    theme(legend.position="top") +
    labs(title = "Bill Length and Bill Depth")

plot2 <- ggplot(penguins, aes(x = bill_length_mm, y = flipper_length_mm, col = species)) +
    geom_point() + 
    theme(legend.position="top") +
    labs(title = "Bill Length and Flipper Length")

plot3 <- ggplot(penguins, aes(x = bill_length_mm, y = body_mass_g, col = species)) +
    geom_point() + 
    theme(legend.position="top") +
    labs(title = "Bill Length and Body Mass")

plot4 <- ggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm, col = species)) +
    geom_point() + 
    theme(legend.position="top") +
    labs(title = "Bill Depth and Flipper Length")

plot5 <- ggplot(penguins, aes(x = bill_depth_mm, y = body_mass_g, col = species)) +
    geom_point() + 
    theme(legend.position="top") + 
    labs(title = "Bill Depth and Body Mass")

plot6 <- ggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, col = species)) +
    geom_point() + 
    theme(legend.position="top") + 
    labs(title = "Flipper Length and Body Mass")

grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, ncol=2, nrow=3)
```
Interestingly, when we break out the plots by species, we can see that many of the feature interactions show clustering between Adelie and Chinstrap penguins (red and green), while Gentoo penguins tend to contrast the other two species for most interactions. This is also confirmed by most of the single-variable distributions split out by species in the plots below. With the exception of the distribution of `bill_length_mm`, distributions for `body_mass_g`, `bill_depth_mm`, and `flipper_length_mm` all show there to be overlapping distributions between Adelie and Chinstrap penguin species.

```{r, message=FALSE, warning=FALSE, fig.width=12, fig.height=10, echo=FALSE}
penguins %>%
  dplyr::select(species, body_mass_g, bill_length_mm, bill_depth_mm, flipper_length_mm) %>%
  ggpairs(aes(color = species))
```
With this in mind, I think it'll be best to *combine the Chinstrap penguin species with the Adelie species* in order for us to create our binary outcome for our logistic regression. Therefore, to do this, we can do the following data manipulation by creating an extra column to bifurcate the species variable:

```{r}
penguins <- penguins %>% 
  mutate(species_rollup = ifelse(species == 'Adelie' | species == 'Chinstrap', 'Adelie-Chinstrap', 'Gentoo'))
```

And now we can see the split between the two new groups of penguins:
```{r, echo=FALSE}
table(penguins$species_rollup)
```

***

**B) Please make sure you are evaluating the independent variables appropriately in deciding which ones should be in the model.**

***

***Checking kurtosis and transforming variables***  

Now that the outcome variable of species has been rolled up into two distinct groups of penguins, the next step is to evaluate the independent variables in the dataset accordingly. A good first step is to take a look at the distributions of each feature to get a sense of kurtosis:

```{r, warning=FALSE, echo=FALSE}
plot7 <- ggplot(penguins, aes(x=body_mass_g)) + 
    geom_histogram(aes(y=..density..),      
                   binwidth=100,
                   colour="gray", fill="white") +
    geom_density(alpha=.7, fill="#619CFF") +
   labs(title = "Body Mass Distribution")

plot8 <- ggplot(penguins, aes(x=bill_length_mm)) + 
    geom_histogram(aes(y=..density..),      
                   binwidth=1,
                   colour="gray", fill="white") +
    geom_density(alpha=.7, fill="#619CFF") +
    labs(title = "Bill Length (mm) Distribution")

plot9 <- ggplot(penguins, aes(x=bill_depth_mm)) + 
    geom_histogram(aes(y=..density..),    
                   binwidth=0.5,
                   colour="gray", fill="white") +
    geom_density(alpha=.7, fill="#619CFF")  +
    labs(title = "Bill Depth (mm) Distribution")

plot10 <- ggplot(penguins, aes(x=flipper_length_mm)) + 
    geom_histogram(aes(y=..density..),    
                   binwidth=2.5,
                   colour="gray", fill="white") +
    geom_density(alpha=.7, fill="#619CFF")  +
    labs(title = "Flipper Length (mm) Distribution")

grid.arrange(plot7, plot8, plot9, plot10, ncol=2, nrow=2)
```

From the above distributions, we can see that most of our continuous variables are quite skewed. In order to alleviate this before subjecting to our logistic regression, we can perform some transformations to make more normal distributions.

```{r}
# transform variables
penguins$bill_length_transformed <- abs(penguins$bill_length_mm - mean(penguins$bill_length_mm))^(1/2)
penguins$flipper_length_transformed <- abs(penguins$flipper_length_mm - mean(penguins$flipper_length_mm))^(1/2)
```

```{r, echo=FALSE}
plot11 <- ggplot(penguins, aes(x=bill_length_transformed)) + 
    geom_histogram(aes(y=..density..),      
                   binwidth=0.15,
                   colour="gray", fill="white") +
    geom_density(alpha=.7, fill="#F8776D") +
    labs(title = "Bill Length -- Transformed")

plot12 <- ggplot(penguins, aes(x=flipper_length_transformed)) + 
    geom_histogram(aes(y=..density..),      
                   binwidth=0.15,
                   colour="gray", fill="white") +
    geom_density(alpha=.7, fill="#F8776D") +
    labs(title = "Flipper Length -- Transformed")


grid.arrange(plot8, plot11, plot10, plot12, ncol=2, nrow=2)
```

As we can see above, we were able to perform a few transformations on `bill_length_mm` and `flipper_length_mm` to make more normal distributions. However, we will have to see if these transformations are interpretable when we run our logistic regression.  

***

***Checking for multicollinearity***  

Additionally, when evaluating the independent variables, it's important to take multicollinearity into consideration. Multicollinearity can impact the variances of our parameter estimates, which could lead to incorrect inferences about relationships between our dependent variable (species) and independent variables. Therefore, I ran a correlation plot to check the collinearity between some of our independent variables.

```{r, echo=FALSE}

penguins_cont <- penguins %>% dplyr::select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g)


correlation = cor(penguins_cont, use = 'pairwise.complete.obs')

corrplot(correlation, method='ellipse')
```

We can see above that `flipper_length` and `body_mass_g` have a pretty strong positive correlation with one another. This makes sense given that typically penguins with larger body mass will have larger flippers. Since we are seeing a bimodal distribution for `flipper_length` which led to a pretty in-depth transformation, we may consider excluding this feature from our logistic regression, given that it also shows such a strong relationship with `body_mass_g`.

***

***Downsampling Adelie-Chinstrap from dataset***  

One final step is to take a quick look at the counts for our binary variable `species_rollup` that we created earlier to help us create our binary logistic regression outcome:

```{r}
table(penguins$species_rollup)
```

Unfortunately, it looks like there's a class imbalance here where there are almost double the amount of Adelie-Chinstrap individuals in our dataset than Gentoo individuals. This could impact our logistic regression outcome and eventual model performance. In order to create a more equal subset of individuals between the two classes, we can downsample the Adelie-Chinstrap group to match the number of Gentoo species at 119. In order to do this, we can run a function in the `caret` package called `downSample()`, which will randomly select 119 individuals from the Adelie-Chinstrap group to use for our model:

```{r}
penguins_rollup_factor <- factor(penguins$species_rollup)
downsample_penguins <- downSample(penguins, penguins_rollup_factor, list = FALSE, yname = "Class")

table(downsample_penguins$species_rollup)
```

Now, we have an equal share of 119 individuals in our new `downsample_penguins` dataset between our two groups. With these adjustments, we are now ready to start running our logistic regression models.

```{r}
downsample_penguins$penguins_species_fnl <- ifelse(downsample_penguins$species_rollup == 'Gentoo', 0, 1)
```

***

***Running the logistic regression***  

First, we'll need to split our `downsample_penguins` dataset into a training and testing set (80% training, 20% testing). This was necessary in order to measure our model performance on our holdout test set later on.  

```{r}
set.seed(1234567)

# utilizing one dataset for all four models
penguins_partition <- createDataPartition(downsample_penguins$species_rollup, p=0.8, list=FALSE)
penguins_training <- downsample_penguins[penguins_partition,]
penguins_testing <- downsample_penguins[-penguins_partition,]
```

Next, after running a few preliminary models that didn't show large differences between the transformed variables I had created and those from the original dataset, I decided to keep the existing variables in order to ease interpretation of the log odds. Additionally, I decided to not use variables such as `bill_depth_mm`, `island`, `sex`, and `year`, since they appear to be overfitting the model and creating fitted probabilities that numerically turned out to be 0 or 1. Therefore, for the first model, I added three variables `bill_length_mm`, `flipper_length_mm`, and `body_mass_g` to the logistic regression and used stepwise selection to determine if other variables should be removed:


```{r, warning=FALSE, cache=TRUE}
model1 <- glm(penguins_species_fnl ~ bill_length_mm +  flipper_length_mm + body_mass_g , data = penguins_training, family = binomial)

model2 <- model1 %>% stepAIC(trace=FALSE)
summary(model2)
```
As we can see, it doesn't look like StepAIC removed any of our less statistically significant variables, since they didn't meet the threshold. However, in model 3, I decided to remove `bill_length_mm` to see if this has an impact on our AIC score.  

However, before doing so, I did want to check my VIF scores in order to check multicollinearity. 
```{r}
# print variable inflation factor score
print('VIF scores of predictors')

VIF(model2)
```

Fortunately, we can see that all VIF scores are quite low (below 5), meaning that interactions with one another are quite low.


```{r, warning=FALSE, cache=TRUE}
model3 <- glm(penguins_species_fnl ~ flipper_length_mm + body_mass_g, data = penguins_training, family = binomial)
summary(model3)
```
After running this third model, we can see a small increase in the AIC. I also noticed through this process that `flipper_length_mm` seemed to be quite predictive of our bifurcated species variable. Therefore, I ran one final model which just exposed `flipper_length_mm` as the explanatory variable:

```{r, warning=FALSE, cache=TRUE}
model4 <- glm(penguins_species_fnl ~ flipper_length_mm, data = penguins_training, family = binomial)
summary(model4)
```
This model showed a slight increase in AIC from our previous models, and I do worry that if this model, or model #3 were to be used it may not yield as accurate predictions as model #1. We can examine these models in the next part during the evaluation stage. However, I'll quickly breakdown some of the log odds information and interpret the variables of these logistic regression models below.

***

**C) Provide variable interpretations in your model**  

***

Given our initial model turned out to be our best parsimonious model (based on AIC), if we examine the summary output, we can find the following:  

+ *Bill Length (mm)* -- as the bill length of an individual penguin in the dataset increases by one millimeter, then the odds of the individual being of the Adelie or Chinstrap species increases by exp(0.39), or 1.47.  

+ *Flipper Length (mm)* -- as the flipper length of an individual penguin in the dataset increases by one millimeter, then the odds of the individual being of the Adelie or Chinstrap species decreases by exp(-0.75), or 0.47.  

+ *Body Mass (g)* -- as the body mass of an individual penguin in the dataset increases by one gram, then the odds of the individual being of the Adelie or Chinstrap species decreases by exp(-0.003), or 0.10.


***

#### Part 2: Logistic Regression evaluation (AUC, TPR, FPR, TNR, FNR and Accuracy)  

***

**A) For your model from #1, please provide: AUC, Accuracy, TPR, FPR, TNR, FNR**

***

Although we won't evaluate the performance of this model on the training dataset, it is good to check to make sure these functions are working properly before subjecting this to the testing set. Therefore, below we will examine the predictions and confusion matrix for our model of choice (model #1):
```{r}
predictTrain = predict(model1, type = "response")
penguins_training$target = round(predictTrain, 1)
table(penguins_training$penguins_species_fnl, predictTrain > 0.5)
```

We can also check the accuracy of the predictions on the training set:
```{r}
penguins_training = penguins_training %>%
  mutate(accuracy = 1*(round(target, 0) == round(penguins_species_fnl, 0)))

paste0('Accuracy on Training Set: ', sum(penguins_training$accuracy)/nrow(penguins_training))
```

***

***Measuring Accuracy, TPR, FPR, TNR, and FNR on testing set***

Now, we can evaluate our chosen model #1 on our holdout testing set. Initially, we'll set our threshold at 0.5, to determine whether or not our predictions should be classified into the Gentoo category (less than or equal to 0.5) or Adelie-Chinstrap category (greater than 0.5):

```{r, cache=TRUE}
predictTest = predict(model1, type = "response", newdata = penguins_testing)
penguins_testing$target = round(predictTest, 1)
confusion_matrix <- table(penguins_testing$penguins_species_fnl, predictTest > 0.5)
confusion_matrix
```

***Calculating TPR, TNR, FPR, and FNR***  

```{r, cache=TRUE}
# tp = true positive
# tn = true negative
# fp = false positive
# fn = false negative

tp <- confusion_matrix[4]
tn <- confusion_matrix[1]
fp <- confusion_matrix[2]
fn <- confusion_matrix[3]
p <- sum(confusion_matrix[3], confusion_matrix[4])
n <- sum(confusion_matrix[1], confusion_matrix[2])

tpr <- tp / p
tnr <- tn / n
fpr <- fp / n
fnr <- fn / p

title_row <- c('True Positive Rate (TPR)', 'True Negative Rate (TNR)', 'False Positive Rate (FPR)', 'False Negative Rate (FNR)')
values <- c(tpr, tnr, fpr, fnr)

results <- data.frame(title_row, values)
colnames(results) <- c('Measure', 'Value')

results
```
After calculating TPR, TNR, FPR, and FNR, it's a good sign to see that both FPR and FNR are quite low. Additionally, the model was very good at classifying penguins in the testing dataset that were of either the Adelie/Chinstrap species (predicted all but one of them correctly), and classified all Gentoo species correctly.


***Accuracy***

```{r, cache=TRUE}
penguins_testing = penguins_testing %>%
  mutate(accuracy = 1*(round(target, 0) == round(penguins_species_fnl, 0)))

paste0('Accuracy on Training Set: ', sum(penguins_testing$accuracy)/nrow(penguins_testing))
```
As we can see above, when checking the accuracy of the predictions on our testing set, we can see that model 1 was roughly 98% accurate in predicting whether or not the penguin was classified as either a Gentoo or Adelie/Chinstrap species.

***Calculating AUC***

We can plot an ROC curve and calculate our AUC by using the `pRoc` package. Below, we were able to plot our thresholds.

![I was having issues with caching when knitting to R, so had to take a picture instead of showing output!](C:/Users/zalexander/Desktop/data622_cunysps/Homework1/AUC-1.jpg)

```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}
roc(penguins_testing$penguins_species_fnl ~ predictTest, plot=TRUE, print.auc=TRUE, col='black', lwd=4, legacy.axes=TRUE)
```


Finally, the AUC of our chosen model #1 is very good, with a value of 0.994, which is very close to 1 and supports our calculation of accuracy that almost all predictions were correct.  


***

#### Part 3: Multinomial Logistic Regression

***

**A) Please fit a multinomial logistic regression where your outcome variable is 'species'.**  
**B) Please be sure to evaluate the independent variables appropriately to fit your best parsimonious model.**  

***

For this last part, we'll use the initial `species` variable to create a multinomial logistic regression model. This way, we do not have to bifurcate our species into two categories, but instead use a different type of logistic regression to obtain predictions for all three species. In order to do this, I decided to take our initial training dataset from Part 1, since it is already split accordingly, and use the `multinom()` function from the `broom` package to run our first model. 

```{r, echo=FALSE}
penguins_training_mod <- penguins_training %>% dplyr::select(-target, -accuracy)
penguins_training_mod$outcome_level = relevel(penguins_training_mod$species, ref = "Chinstrap")
```

***

***Model 1***

In this initial model, I kept all variables in, just to get a baseline AIC to compare future models on the training data. 
```{r, cache=TRUE}
multinom_model1 <- multinom(outcome_level ~ bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g + sex + year + bill_length_transformed + flipper_length_transformed, data = penguins_training_mod)
tidy(multinom_model1, conf.int = FALSE, conf.level = 0.95, exponentiate = FALSE)
summary(multinom_model1)
```

We can see that the AIC value is around 36, and when we look at the p-values and summary statistics, we can immediately see that it'll be best to remove variables such as `year` and `sex`, both of which didn't perform well in our binomial logistic regression earlier, as well as `bill_length_transformed` and `flipper_length_transformed`, both of which have high p-values here as well.  

***

***Model 2***

When we re-run the model, removing these variables, we can see that there is an improvement in AIC (from 36 to 20). However, we'll continue to remove a few variables to see if we can improve our model even more.
```{r, cache=TRUE}
multinom_model2 <- multinom(outcome_level ~ bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, data = penguins_training_mod)
tidy(multinom_model2, conf.int = FALSE, conf.level = 0.95, exponentiate = FALSE)
summary(multinom_model2)
```

***

***Model 3***

In our third iteration of our model, we decided to remove `flipper_length_mm`, which seemed to have the highest p-value and was likely exposing our model to multicollinearity issues with `body_mass_g`, which we could see from our initial variable examination earlier in our model building.  


```{r, cache=TRUE}
multinom_model3 <- multinom(outcome_level ~ bill_length_mm + bill_depth_mm  + body_mass_g, data = penguins_training_mod)
tidy(multinom_model3, conf.int = FALSE, conf.level = 0.95, exponentiate = FALSE)
summary(multinom_model3)
```

We can see that by removing `flipper_length_mm`, AIC continues to improve (dropping from 20 to 16). **This final model yielded our lowest AIC and contains `bill_length_mm` `bill_depth_mm` and `body_mass_g` as our chosen independent variables for our best parsimonious model**.  

***

**C) Please be sure to interpret your variables in the model** 

***



Given our third multinomial logisitic regression model turned out to be our best parsimonious model (based on AIC), if we examine the summary output, we can find the following:  

+ *Bill Length (mm)* -- A one millimeter increase in bill length is associated with the decrease in the log odds of being classified as the Adelie species vs. Gentoo species in the amount of 48.55. Similarly, a one millimeter increase in bill length is associated with the increase in the log odds of being classified as the Chinstrap species vs. Gentoo species by 10.22. Essentially, as bill length increases, it's less likely to be classified as an Adelie species than Gentoo species. Similarly, as bill length increases, the log odds become more certain to be classified as a Chinstrap species than Gentoo species. This can be confirmed by the initial overlapping distributions represented in the data exploration part of the assignment (Part 1). 

+ *Bill Depth (mm)* -- A one millimeter increase in bill depth is associated with the increase in the log odds of being classified as the Adelie species vs. Gentoo species in the amount of 97.40. Similarly, a one millimeter increase in bill length is associated with the increase in the log odds of being classified as the Chinstrap species vs. Gentoo species by 4.55. Essentially, as bill depth increases, it's more likely to be classified as an Adelie species than Gentoo species. Similarly, as bill depth increases, the log odds become more certain to be classified as a Chinstrap species than Gentoo species. This can be confirmed by the initial overlapping distributions represented in the data exploration part of the assignment (Part 1). 

+ *Body Mass (g)* -- A one gram increase in body mass is associated with the increase in the log odds of being classified as the Adelie species vs. Gentoo species in the amount of 0.09. Similarly, a one gram increase in body mass is associated with the decrease in the log odds of being classified as the Chinstrap species vs. Gentoo species by 0.11. Essentially, as body mass increases, it's more likely to be classified as an Gentoo species over either Adelie or Chinstrap species. This can be confirmed by the initial overlapping distributions represented in the data exploration part of the assignment (Part 1). 

***

#### Part 4: Extra Credit  

***

**Extra credit: what would be some of the fit statistics you would want to evaluate for your model in question #3? Feel free to share whatever you can provide.**  

***

Before discussing fit statistics, we can first create predictions on our holdout test set based on our model #3 in the last section. We can create a dataframe that shows the computed probabilities for an individual being classified into each class.

```{r}
predictTest_mod = predict(multinom_model3, type = "probs", newdata = penguins_testing)
predictTest_mod = data.frame(predictTest_mod)
```

Here's the first five values of the dataframe:

```{r}
head(predictTest_mod)
```
As we can see above, probabilities falling closer to 1 will be utilized for classification. Therefore, if we take the maximum value of the three columns for each row, we can then estimate a classification for our target set:

```{r}
target_test <- colnames(predictTest_mod)[apply(predictTest_mod,1,which.max)]
penguins_testing$target = target_test

cmx_test <- table(penguins_testing$target, penguins_testing$target == penguins_testing$species)
cmx_test
```

We can see from the confusion matrix generated, that the model estimated the correct classification for all individuals in our test set. This indicates that our model is working quite well.  

***

**Fit Statistics for Multinomial Logisitic Regression**  

Some of the fit statistics that you'd want to evaluate for the model produced in part 3 would be based on the predicted results. For instance, now that we have these predictions, we could test the **goodness of fit** by running  a Pearson's Chi-squared test on these predictions and the categories. This would produce an interpretable $X^2$ value. It would also be possible to calculate a psuedo R square values for each of our species -- we'd interpret it a bit differently than traditional OLS, but would be available for us to make some assumptions about the proportion of variance of species that can be explained by the independent variables.